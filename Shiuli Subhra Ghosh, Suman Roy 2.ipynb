{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00d64c45",
   "metadata": {},
   "source": [
    "# Shiuli Subhra Ghosh(MDS202035), Suman Roy(MDS202041)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01be2722",
   "metadata": {},
   "source": [
    "# Parity Checker using Deep Neural Network \n",
    "## Date: 19.11.2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe7c460",
   "metadata": {},
   "source": [
    "## Data Set Generator train (n = 2000), test (n = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23836b16",
   "metadata": {},
   "source": [
    "Algorithm used for generate the randomized data set:\n",
    "- First we have chosen 2050/5050 (including test data points) random integers in between the range 0 and 100000. \n",
    "- Then we have obtained the binary representation for each numbers and converted it in list of strings.\n",
    "- Then while converting the list of string to list of list, we have randomly shuffeled each data point. \n",
    "- Finally we have converted in numpy 2-D array and store it in a Data Frame\n",
    "- We also saved the simulated data in **.csv** format ('gen2000.csv' and 'gen5000.csv') and these 2 data sets were used in for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "84dfe29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "random.seed(42)\n",
    " \n",
    "n = 64\n",
    "t = [random.randint(0, 100000) for p in range(0, 2050)]\n",
    "l = [bin(x)[2:].rjust(n, '0') for x in t]\n",
    "\n",
    "def Convert(string):\n",
    "    list1=[]\n",
    "    list1[:0]=string\n",
    "    return list1\n",
    "\n",
    "for i in range(len(l)):\n",
    "    ls = Convert(l[i])\n",
    "    random.shuffle(ls)\n",
    "    l[i] = np.array(list(map(int,ls)))\n",
    "    \n",
    "l = np.array(l)    \n",
    "    \n",
    "df = pd.DataFrame(l)   \n",
    "\n",
    "y = [sum(i)%2 for i in l]  # 0 means Even parity 1 means odd parity\n",
    "df['Y'] = y\n",
    "\n",
    "df.to_csv('gen2000.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b70989",
   "metadata": {},
   "source": [
    "## Data Set Generator train (n = 5000) test (n = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f3c9d88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "n = 64\n",
    "t = [random.randint(0, 100000) for p in range(0, 5050)]\n",
    "l = [bin(x)[2:].rjust(n, '0') for x in t]\n",
    "\n",
    "def Convert(string):\n",
    "    list1=[]\n",
    "    list1[:0]=string\n",
    "    return list1\n",
    "\n",
    "for i in range(len(l)):\n",
    "    ls = Convert(l[i])\n",
    "    random.shuffle(ls)\n",
    "    l[i] = np.array(list(map(int,ls)))\n",
    "    \n",
    "l = np.array(l)    \n",
    "    \n",
    "df = pd.DataFrame(l)   \n",
    "\n",
    "y = [sum(i)%2 for i in l]  # 0 means Even parity 1 means odd parity\n",
    "df['Y'] = y\n",
    "\n",
    "df.to_csv('gen5000.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bceac88",
   "metadata": {},
   "source": [
    "## Parity Checker using DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024ba61b",
   "metadata": {},
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e2d2a80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from numpy import vstack\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Sigmoid\n",
    "from torch.nn import Module\n",
    "from torch.optim import Adam\n",
    "from torch.nn import BCELoss\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "from torch.nn.init import xavier_uniform_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b349fa6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32335754",
   "metadata": {},
   "source": [
    "### Data Set Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f20d0f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSVDataset(Dataset):\n",
    "    # load the dataset\n",
    "    def __init__(self, file_name):\n",
    "        # load the csv file as a dataframe\n",
    "        df = read_csv(file_name, header=0, index_col = 0)\n",
    "        # store the inputs and outputs\n",
    "        self.X = df.values[:, :-1]\n",
    "        self.y = df.values[:, -1]\n",
    "        # ensure input data is floats\n",
    "        self.X = self.X.astype('float32')\n",
    "        # label encode target and ensure the values are floats\n",
    "        self.y = LabelEncoder().fit_transform(self.y)\n",
    "        self.y = self.y.astype('float32')\n",
    "        self.y = self.y.reshape((len(self.y), 1))\n",
    "        \n",
    "        # number of rows in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    " \n",
    "    # get a row at an index\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.X[idx], self.y[idx]]\n",
    " \n",
    "    # get indexes for train and test rows\n",
    "    def get_splits(self, n_test=50):\n",
    "        # determine sizes\n",
    "        test_size = n_test\n",
    "        train_size = len(self.X) - test_size\n",
    "        # calculate the split\n",
    "        return random_split(self, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759ab002",
   "metadata": {},
   "source": [
    "### Model Definition (Two hidden layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243aacd9",
   "metadata": {},
   "source": [
    "Here, we have used 2 hidden layers in this case. In the first hidden layers we have taken 100 neurons and in the 2nd hidden layer we have taken 10 neurons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "036ee6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(Module):\n",
    "    # define model elements\n",
    "    def __init__(self, n_inputs):\n",
    "        super(MLP, self).__init__()\n",
    "        # input to first hidden layer\n",
    "        self.hidden1 = Linear(n_inputs, 100)\n",
    "        kaiming_uniform_(self.hidden1.weight, nonlinearity='relu')\n",
    "        self.act1 = ReLU()\n",
    "        # second hidden layer\n",
    "        self.hidden2 = Linear(100, 10)\n",
    "        kaiming_uniform_(self.hidden2.weight, nonlinearity='relu')\n",
    "        self.act2 = ReLU()\n",
    "        # third hidden layer and output\n",
    "        self.hidden3 = Linear(10, 1)\n",
    "        xavier_uniform_(self.hidden3.weight)\n",
    "        self.act3 = Sigmoid()\n",
    " \n",
    "    # forward propagate input\n",
    "    def forward(self, X):\n",
    "        # input to first hidden layer\n",
    "        X = self.hidden1(X)\n",
    "        X = self.act1(X)\n",
    "         # second hidden layer\n",
    "        X = self.hidden2(X)\n",
    "        X = self.act2(X)\n",
    "        # third hidden layer and output\n",
    "        X = self.hidden3(X)\n",
    "        X = self.act3(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49f6356",
   "metadata": {},
   "source": [
    "### Data Set preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e551269f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(file_name):\n",
    "    # load the dataset\n",
    "    dataset = CSVDataset(file_name)\n",
    "    # calculate split\n",
    "    train, test = dataset.get_splits()\n",
    "    # prepare data loaders\n",
    "    train_dl = DataLoader(train, batch_size=64, shuffle=True)\n",
    "    test_dl = DataLoader(test, batch_size=64, shuffle=False)\n",
    "    return train_dl, test_dl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace35afe",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3004e63b",
   "metadata": {},
   "source": [
    "We have used Adam optimizer and BCELoss as we have binary class classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ccf71df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_dl, model):\n",
    "    # define the optimization\n",
    "    criterion = BCELoss()\n",
    "    optimizer = Adam(model.parameters())\n",
    "    # enumerate epochs\n",
    "    for epoch in range(10):\n",
    "        # enumerate mini batches\n",
    "        for i, (inputs, targets) in enumerate(train_dl):\n",
    "            # clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "            # compute the model output\n",
    "            yhat = model(inputs)\n",
    "            # calculate loss\n",
    "            loss = criterion(yhat, targets)\n",
    "            # credit assignment\n",
    "            loss.backward()\n",
    "            # update model weights\n",
    "            optimizer.step()\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211b2c6b",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1c29cade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "def evaluate_model(test_dl, model):\n",
    "    predictions, actuals = list(), list()\n",
    "    for i, (inputs, targets) in enumerate(test_dl):\n",
    "        # evaluate the model on the test set\n",
    "        yhat = model(inputs)\n",
    "        # retrieve numpy array\n",
    "        yhat = yhat.detach().numpy()\n",
    "        actual = targets.numpy()\n",
    "        actual = actual.reshape((len(actual), 1))\n",
    "        # round to class values\n",
    "        yhat = yhat.round()\n",
    "        # store\n",
    "        predictions.append(yhat)\n",
    "        actuals.append(actual)\n",
    "    predictions, actuals = vstack(predictions), vstack(actuals)\n",
    "    # calculate accuracy\n",
    "    acc = accuracy_score(actuals, predictions)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c031a5dc",
   "metadata": {},
   "source": [
    "### Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d1b6ef86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(row, model):\n",
    "    # convert row to data\n",
    "    row = Tensor([row])\n",
    "    # make prediction\n",
    "    yhat = model(row)\n",
    "    # retrieve numpy array\n",
    "    yhat = yhat.detach().numpy()\n",
    "    return yhat   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb22b73",
   "metadata": {},
   "source": [
    "# Driver Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ed70e0",
   "metadata": {},
   "source": [
    "#### First running the model on 'gen2000.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "1c8bd213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 50\n"
     ]
    }
   ],
   "source": [
    "file_name = r'gen2000.csv'\n",
    "train, test = prepare_data(file_name) \n",
    "print(len(train.dataset), len(test.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "6b2f4340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7320, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6294, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7141, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6292, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6474, grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = MLP(64)\n",
    "train_model(train, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "5cf43509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_Accuracy: 54.000\n",
      "train_Accuracy: 71.700\n"
     ]
    }
   ],
   "source": [
    "accuracy = evaluate_model(test, model)*100\n",
    "accuracy_1 = evaluate_model(train , model)*100\n",
    "print('test_Accuracy: %.3f' % accuracy)\n",
    "print('train_Accuracy: %.3f' % accuracy_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "c18a0b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_matrix = pd.DataFrame(index = ('test_accuracy','train_accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e4792195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gen2000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_accuracy</th>\n",
       "      <td>71.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                gen2000\n",
       "test_accuracy      54.0\n",
       "train_accuracy     71.7"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accu = [accuracy,accuracy_1]\n",
    "Accuracy_matrix['gen2000'] = accu\n",
    "Accuracy_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca334016",
   "metadata": {},
   "source": [
    "#### Now, training on 'gen5000.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "752412b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 50\n"
     ]
    }
   ],
   "source": [
    "file_name = r'gen5000.csv'\n",
    "train, test = prepare_data(file_name) \n",
    "print(len(train.dataset), len(test.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "9ce0e96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7038, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6671, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6774, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6666, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6320, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6588, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5466, grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = MLP(64)\n",
    "train_model(train, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "3e8e624c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_Accuracy: 58.000\n",
      "train_Accuracy: 70.400\n"
     ]
    }
   ],
   "source": [
    "accuracy = evaluate_model(test, model)*100\n",
    "accuracy_1 = evaluate_model(train , model)*100\n",
    "print('test_Accuracy: %.3f' % accuracy)\n",
    "print('train_Accuracy: %.3f' % accuracy_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0c7e22",
   "metadata": {},
   "source": [
    "# Accumulating train and test accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "8b860634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gen2000</th>\n",
       "      <th>gen5000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>54.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_accuracy</th>\n",
       "      <td>71.7</td>\n",
       "      <td>70.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                gen2000  gen5000\n",
       "test_accuracy      54.0     58.0\n",
       "train_accuracy     71.7     70.4"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accu = [accuracy,accuracy_1]\n",
    "Accuracy_matrix['gen5000'] = accu\n",
    "Accuracy_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a75269",
   "metadata": {},
   "source": [
    "We can observe that for both the Data sets, the training accuracy is nearly 70% and the test accuracy is in between 45% to 55%. It is because, for 64 bit binary numbers, there are $2^{64}$ numbers of elements are present in space and we are randomly selecting 2000 for the first and 5000 for the second case. So, it is not possible to obtain greater accuracy in case of test set as the training is totally randomised in nature. \n",
    "- Taking 2000 data points for training is equivalent to take 5000 data points for training.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8265519",
   "metadata": {},
   "source": [
    "# Implementing Same Architecture as the Manual Implementation (One hidden layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebcdb5c",
   "metadata": {},
   "source": [
    "Here, I have tried to check if we train the NN with same architecture what is the loss and the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "b39cfcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_1(Module):\n",
    "    # define model elements\n",
    "    def __init__(self, n_inputs):\n",
    "        super(MLP_1, self).__init__()\n",
    "        # input to first hidden layer\n",
    "        self.hidden1 = Linear(n_inputs, 96)\n",
    "        kaiming_uniform_(self.hidden1.weight, nonlinearity='relu')\n",
    "        self.act1 = ReLU()\n",
    "        # second hidden layer\n",
    "        self.hidden2 = Linear(96, 1)\n",
    "        xavier_uniform_(self.hidden2.weight)\n",
    "        self.act2 = Sigmoid()\n",
    " \n",
    "    # forward propagate input\n",
    "    def forward(self, X):\n",
    "        # input to first hidden layer\n",
    "        X = self.hidden1(X)\n",
    "        X = self.act1(X)\n",
    "         # second hidden layer\n",
    "        X = self.hidden2(X)\n",
    "        X = self.act2(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "f0cb9151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 50\n"
     ]
    }
   ],
   "source": [
    "file_name = r'gen2000.csv'\n",
    "train, test = prepare_data(file_name) \n",
    "print(len(train.dataset), len(test.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "95cf8d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7238, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6546, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6850, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7461, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7189, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7098, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6142, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6671, grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = MLP_1(64)\n",
    "train_model(train, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "df84d783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_Accuracy: 52.000\n",
      "train_Accuracy: 65.150\n"
     ]
    }
   ],
   "source": [
    "accuracy = evaluate_model(test, model)*100\n",
    "accuracy_1 = evaluate_model(train , model)*100\n",
    "print('test_Accuracy: %.3f' % accuracy)\n",
    "print('train_Accuracy: %.3f' % accuracy_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b486d6e9",
   "metadata": {},
   "source": [
    "After training it is evident that the learning is not perfect even if we are using the same architecture as we used for the manual implementation. The accuracy is almost equvant to the previous network with 2 hidden layers. So, from here, we can also verify that one hidden layer is sufficient to implement any logic circuits. \n",
    "- Finally our manually designed network is definitely performing better than the Deep network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
